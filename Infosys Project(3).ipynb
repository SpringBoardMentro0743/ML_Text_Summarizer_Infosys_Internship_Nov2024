{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94d5614-ab5c-42a2-adec-8ff6123b2355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\biswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\biswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\biswa\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to import necessary libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c7764a8-7dfa-46e9-9b82-28da3f55191f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename                                            content\n",
       "0  001.txt  Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1  002.txt  Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2  003.txt  Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3  004.txt  High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4  005.txt  Pernod takeover talk lifts Domecq\\n\\nShares in..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the main directory path\n",
    "path = r\"E:\\Infosys project\\BBC News Summary\\News Articles\"\n",
    "\n",
    "data = []\n",
    "\n",
    "# Loop through each subdirectory in the main directory\n",
    "for folder in os.listdir(path):\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        # Loop through each file in the subdirectory\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "                    content = file.read()\n",
    "                    data.append({\"filename\": filename, \"content\": content})\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6782ebbb-76bd-4cb9-ad34-339d9315da91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2225\n",
      "Sample content:\n",
      " Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
      "\n",
      "Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n",
      "\n",
      "Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n",
      "\n",
      "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the number of documents and view a sample\n",
    "print(\"Number of documents:\", len(df))\n",
    "print(\"Sample content:\\n\", df['content'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04a61b3-af8a-488e-b294-4564ff75750d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cleaned_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>dollar gain greenspan speech dollar hit highes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>high fuel price hit ba profit british airway b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename                                    cleaned_content\n",
       "0  001.txt  ad sale boost time warner profit quarterly pro...\n",
       "1  002.txt  dollar gain greenspan speech dollar hit highes...\n",
       "2  003.txt  yukos unit buyer face loan claim owner embattl...\n",
       "3  004.txt  high fuel price hit ba profit british airway b...\n",
       "4  005.txt  pernod takeover talk lift domecq share uk drin..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define cleaning functions\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)  # Remove single characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return ' '.join([word for word in tokens if word not in stop_words])\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in tokens])\n",
    "\n",
    "# Apply the functions\n",
    "df['cleaned_content'] = df['content'].apply(clean_text).apply(remove_stop_words).apply(lemmatize_text)\n",
    "df[['filename', 'cleaned_content']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5fc0d58-6932-4647-88e4-dc160a0ee09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>[ad sale boost time warner profit quarterly pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>[dollar gain greenspan speech dollar hit highe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>[yukos unit buyer face loan claim owner embatt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>[high fuel price hit ba profit british airway ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>[pernod takeover talk lift domecq share uk dri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename                                          sentences\n",
       "0  001.txt  [ad sale boost time warner profit quarterly pr...\n",
       "1  002.txt  [dollar gain greenspan speech dollar hit highe...\n",
       "2  003.txt  [yukos unit buyer face loan claim owner embatt...\n",
       "3  004.txt  [high fuel price hit ba profit british airway ...\n",
       "4  005.txt  [pernod takeover talk lift domecq share uk dri..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize into sentences for summarization at the sentence level\n",
    "df['sentences'] = df['cleaned_content'].apply(sent_tokenize)\n",
    "df[['filename', 'sentences']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ccf564d-bbce-4587-9cf4-1a0f4730176a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix shape: (2225, 26243)\n"
     ]
    }
   ],
   "source": [
    "# Convert cleaned text to TF-IDF matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(df['cleaned_content'])\n",
    "print(\"TF-IDF Matrix shape:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fda340d-ccd5-4cfe-b68e-90bf186f58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file for later use\n",
    "df.to_csv(\"processed_bbc_news_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a180e20-acb1-435f-bbb0-f6d32b733622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filename                                            content  \\\n",
      "0  001.txt  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
      "1  002.txt  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
      "2  003.txt  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
      "3  004.txt  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
      "4  005.txt  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
      "\n",
      "                                     cleaned_content  \\\n",
      "0  ad sale boost time warner profit quarterly pro...   \n",
      "1  dollar gain greenspan speech dollar hit highes...   \n",
      "2  yukos unit buyer face loan claim owner embattl...   \n",
      "3  high fuel price hit ba profit british airway b...   \n",
      "4  pernod takeover talk lift domecq share uk drin...   \n",
      "\n",
      "                                           sentences  \n",
      "0  ['ad sale boost time warner profit quarterly p...  \n",
      "1  ['dollar gain greenspan speech dollar hit high...  \n",
      "2  ['yukos unit buyer face loan claim owner embat...  \n",
      "3  ['high fuel price hit ba profit british airway...  \n",
      "4  ['pernod takeover talk lift domecq share uk dr...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load preprocessed data\n",
    "df = pd.read_csv(\"processed_bbc_news_summary.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba8b861-0490-4cb0-9375-ff631af54a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix shape: (2225, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust `max_features` based on your dataset\n",
    "tfidf_matrix = vectorizer.fit_transform(df['content'])\n",
    "\n",
    "# Check the shape of the TF-IDF matrix\n",
    "print(\"TF-IDF Matrix shape:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70388e82-5fdb-415f-8c2d-811b95c769a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.', 'The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales.', 'TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.', 'Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.', 'Time Warner said on Friday that it now owns 8% of search-engine Google.', 'But its own internet business, AOL, had has mixed fortunes.', 'It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.', \"However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues.\", \"It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband.\", 'TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.', \"Time Warner's fourth quarter profits were slightly better than analysts' expectations.\", 'But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results.', 'For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn.', '\"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said.', 'For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.', 'TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators.', 'It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC.', 'The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m.', \"It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue.\", 'It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "df['sentences'] = df['content'].apply(sent_tokenize)\n",
    "print(df['sentences'][0])  # Example: print sentences from the first document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f38be9c-1636-418c-a816-457f5dd0f283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.', 2867.0), ('The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m.', 2774.8333333333335), ('It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.', 2700.5238095238096), ('Time Warner said on Friday that it now owns 8% of search-engine Google.', 2667.3076923076924), (\"It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband.\", 2572.4814814814813)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sentence_scores(content, vectorizer, tfidf_matrix):\n",
    "    scores = []\n",
    "    sentences = sent_tokenize(content)\n",
    "    tfidf_array = tfidf_matrix.toarray()\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        score = np.mean([vectorizer.vocabulary_.get(word.lower(), 0) for word in words])\n",
    "        scores.append((sentence, score))\n",
    "    return sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Example: Calculate scores for the first document\n",
    "first_doc_scores = sentence_scores(df['content'][0], vectorizer, tfidf_matrix[0])\n",
    "print(first_doc_scores[:5])  # Top 5 scored sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89d0b11-b17d-49ba-aaa0-eac0d0d0b46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n"
     ]
    }
   ],
   "source": [
    "def extract_summary(content, vectorizer, tfidf_matrix, n_sentences=3):\n",
    "    scored_sentences = sentence_scores(content, vectorizer, tfidf_matrix)\n",
    "    top_sentences = sorted(scored_sentences[:n_sentences], key=lambda x: content.index(x[0]))\n",
    "    summary = \" \".join([sentence for sentence, score in top_sentences])\n",
    "    return summary\n",
    "\n",
    "# Example: Summarize the first document\n",
    "summary = extract_summary(df['content'][0], vectorizer, tfidf_matrix[0], n_sentences=3)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "015d0ab2-f7b3-4111-a84e-85aeecd01b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  \\\n",
      "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
      "1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
      "2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
      "3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
      "4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
      "\n",
      "                                             summary  \n",
      "0  It lost 464,000 subscribers in the fourth quar...  \n",
      "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  \n",
      "2  Legal experts said Rosneft's purchase of Yugan...  \n",
      "3  However, it said sales would be better than pr...  \n",
      "4  Reports in the Wall Street Journal and the Fin...  \n"
     ]
    }
   ],
   "source": [
    "df['summary'] = df['content'].apply(lambda x: extract_summary(x, vectorizer, tfidf_matrix, n_sentences=3))\n",
    "print(df[['content', 'summary']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb7191ee-00ff-46c8-8555-f435e43c310a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge-score) (1.25.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge-score) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge-score) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge-score) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (pyproject.toml): started\n",
      "  Building wheel for rouge-score (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24970 sha256=1efab56e5985adf8c083b0dd3ef1244dd3ab202bb32eab85caaab1a862ee58fa\n",
      "  Stored in directory: c:\\users\\biswa\\appdata\\local\\pip\\cache\\wheels\\1e\\19\\43\\8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score\n",
      "Successfully installed absl-py-2.1.0 rouge-score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ae98db5-655e-4215-b3ca-89d5a388ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"extractive_summaries.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad429c-503c-424e-8204-b141f3ae44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "for i in range(len(df)):\n",
    "    scores = scorer.score(df['reference_summary'][i], df['summary'][i])\n",
    "    print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed6c02fe-cdf8-4868-aa67-51c00140ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the updated CSV with reference summaries\n",
    "df = pd.read_csv(\"extractive_summaries.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a226517-97e2-414d-8b3b-f947c7b63204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filename                                            content  \\\n",
      "0  001.txt  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
      "1  002.txt  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
      "2  003.txt  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
      "3  004.txt  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
      "4  005.txt  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
      "\n",
      "                                     cleaned_content  \\\n",
      "0  ad sale boost time warner profit quarterly pro...   \n",
      "1  dollar gain greenspan speech dollar hit highes...   \n",
      "2  yukos unit buyer face loan claim owner embattl...   \n",
      "3  high fuel price hit ba profit british airway b...   \n",
      "4  pernod takeover talk lift domecq share uk drin...   \n",
      "\n",
      "                                           sentences  \\\n",
      "0  ['Ad sales boost Time Warner profit\\n\\nQuarter...   \n",
      "1  ['Dollar gains on Greenspan speech\\n\\nThe doll...   \n",
      "2  ['Yukos unit buyer faces loan claim\\n\\nThe own...   \n",
      "3  [\"High fuel prices hit BA's profits\\n\\nBritish...   \n",
      "4  [\"Pernod takeover talk lifts Domecq\\n\\nShares ...   \n",
      "\n",
      "                                             summary  \n",
      "0  It lost 464,000 subscribers in the fourth quar...  \n",
      "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  \n",
      "2  Legal experts said Rosneft's purchase of Yugan...  \n",
      "3  However, it said sales would be better than pr...  \n",
      "4  Reports in the Wall Street Journal and the Fin...  \n",
      "Summary column examples:\n",
      "Original: Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
      "\n",
      "Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\n",
      "\n",
      "Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\n",
      "\n",
      "TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
      "\n",
      "Summary: It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\n",
      "--------------------------------------------------\n",
      "Original: Dollar gains on Greenspan speech\n",
      "\n",
      "The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\n",
      "\n",
      "And Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. \"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"He's taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\n",
      "\n",
      "Worries about the deficit concerns about China do, however, remain. China's currency remains pegged to the dollar and the US currency's sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing's policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve's decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US's yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.\n",
      "\n",
      "Summary: Dollar gains on Greenspan speech\n",
      "\n",
      "The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise. China's currency remains pegged to the dollar and the US currency's sharp falls in recent months have therefore made Chinese export prices highly competitive. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy.\n",
      "--------------------------------------------------\n",
      "Original: Yukos unit buyer faces loan claim\n",
      "\n",
      "The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (£479m) loan.\n",
      "\n",
      "State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets. Rosneft already faces a similar $540m repayment demand from foreign banks. Legal experts said Rosneft's purchase of Yugansk would include such obligations. \"The pledged assets are with Rosneft, so it will have to pay real money to the creditors to avoid seizure of Yugansk assets,\" said Moscow-based US lawyer Jamie Firestone, who is not connected to the case. Menatep Group's managing director Tim Osborne told the Reuters news agency: \"If they default, we will fight them where the rule of law exists under the international arbitration clauses of the credit.\"\n",
      "\n",
      "Rosneft officials were unavailable for comment. But the company has said it intends to take action against Menatep to recover some of the tax claims and debts owed by Yugansk. Yukos had filed for bankruptcy protection in a US court in an attempt to prevent the forced sale of its main production arm. The sale went ahead in December and Yugansk was sold to a little-known shell company which in turn was bought by Rosneft. Yukos claims its downfall was punishment for the political ambitions of its founder Mikhail Khodorkovsky and has vowed to sue any participant in the sale.\n",
      "\n",
      "Summary: Legal experts said Rosneft's purchase of Yugansk would include such obligations. Menatep Group's managing director Tim Osborne told the Reuters news agency: \"If they default, we will fight them where the rule of law exists under the international arbitration clauses of the credit.\" The sale went ahead in December and Yugansk was sold to a little-known shell company which in turn was bought by Rosneft.\n",
      "--------------------------------------------------\n",
      "Original: High fuel prices hit BA's profits\n",
      "\n",
      "British Airways has blamed high fuel prices for a 40% drop in profits.\n",
      "\n",
      "Reporting its results for the three months to 31 December 2004, the airline made a pre-tax profit of £75m ($141m) compared with £125m a year earlier. Rod Eddington, BA's chief executive, said the results were \"respectable\" in a third quarter when fuel costs rose by £106m or 47.3%. BA's profits were still better than market expectation of £59m, and it expects a rise in full-year revenues.\n",
      "\n",
      "To help offset the increased price of aviation fuel, BA last year introduced a fuel surcharge for passengers.\n",
      "\n",
      "In October, it increased this from £6 to £10 one-way for all long-haul flights, while the short-haul surcharge was raised from £2.50 to £4 a leg. Yet aviation analyst Mike Powell of Dresdner Kleinwort Wasserstein says BA's estimated annual surcharge revenues - £160m - will still be way short of its additional fuel costs - a predicted extra £250m. Turnover for the quarter was up 4.3% to £1.97bn, further benefiting from a rise in cargo revenue. Looking ahead to its full year results to March 2005, BA warned that yields - average revenues per passenger - were expected to decline as it continues to lower prices in the face of competition from low-cost carriers. However, it said sales would be better than previously forecast. \"For the year to March 2005, the total revenue outlook is slightly better than previous guidance with a 3% to 3.5% improvement anticipated,\" BA chairman Martin Broughton said. BA had previously forecast a 2% to 3% rise in full-year revenue.\n",
      "\n",
      "It also reported on Friday that passenger numbers rose 8.1% in January. Aviation analyst Nick Van den Brul of BNP Paribas described BA's latest quarterly results as \"pretty modest\". \"It is quite good on the revenue side and it shows the impact of fuel surcharges and a positive cargo development, however, operating margins down and cost impact of fuel are very strong,\" he said. Since the 11 September 2001 attacks in the United States, BA has cut 13,000 jobs as part of a major cost-cutting drive. \"Our focus remains on reducing controllable costs and debt whilst continuing to invest in our products,\" Mr Eddington said. \"For example, we have taken delivery of six Airbus A321 aircraft and next month we will start further improvements to our Club World flat beds.\" BA's shares closed up four pence at 274.5 pence.\n",
      "\n",
      "Summary: However, it said sales would be better than previously forecast. It also reported on Friday that passenger numbers rose 8.1% in January. \"For example, we have taken delivery of six Airbus A321 aircraft and next month we will start further improvements to our Club World flat beds.\"\n",
      "--------------------------------------------------\n",
      "Original: Pernod takeover talk lifts Domecq\n",
      "\n",
      "Shares in UK drinks and food firm Allied Domecq have risen on speculation that it could be the target of a takeover by France's Pernod Ricard.\n",
      "\n",
      "Reports in the Wall Street Journal and the Financial Times suggested that the French spirits firm is considering a bid, but has yet to contact its target. Allied Domecq shares in London rose 4% by 1200 GMT, while Pernod shares in Paris slipped 1.2%. Pernod said it was seeking acquisitions but refused to comment on specifics.\n",
      "\n",
      "Pernod's last major purchase was a third of US giant Seagram in 2000, the move which propelled it into the global top three of drinks firms. The other two-thirds of Seagram was bought by market leader Diageo. In terms of market value, Pernod - at 7.5bn euros ($9.7bn) - is about 9% smaller than Allied Domecq, which has a capitalisation of £5.7bn ($10.7bn; 8.2bn euros). Last year Pernod tried to buy Glenmorangie, one of Scotland's premier whisky firms, but lost out to luxury goods firm LVMH. Pernod is home to brands including Chivas Regal Scotch whisky, Havana Club rum and Jacob's Creek wine. Allied Domecq's big names include Malibu rum, Courvoisier brandy, Stolichnaya vodka and Ballantine's whisky - as well as snack food chains such as Dunkin' Donuts and Baskin-Robbins ice cream. The WSJ said that the two were ripe for consolidation, having each dealt with problematic parts of their portfolio. Pernod has reduced the debt it took on to fund the Seagram purchase to just 1.8bn euros, while Allied has improved the performance of its fast-food chains.\n",
      "\n",
      "Summary: Reports in the Wall Street Journal and the Financial Times suggested that the French spirits firm is considering a bid, but has yet to contact its target. Pernod's last major purchase was a third of US giant Seagram in 2000, the move which propelled it into the global top three of drinks firms. The WSJ said that the two were ripe for consolidation, having each dealt with problematic parts of their portfolio.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"extractive_summaries.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check if the `summary` column contains meaningful data\n",
    "print(\"Summary column examples:\")\n",
    "for i in range(5):\n",
    "    print(f\"Original: {df['content'][i]}\")\n",
    "    print(f\"Summary: {df['summary'][i]}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74ee54bc-7baa-4951-809a-e572efc4c756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   content_word_count  summary_word_count\n",
      "0                 421                  62\n",
      "1                 384                  71\n",
      "2                 264                  65\n",
      "3                 406                  47\n",
      "4                 265                  72\n"
     ]
    }
   ],
   "source": [
    "# Check word counts\n",
    "df['content_word_count'] = df['content'].apply(lambda x: len(str(x).split()))\n",
    "df['summary_word_count'] = df['summary'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Display word counts\n",
    "print(df[['content_word_count', 'summary_word_count']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "787d31cd-eaee-47e6-9334-501327e81d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for row 0: 0.6257514562660176\n",
      "Similarity for row 1: 0.7361349546279353\n",
      "Similarity for row 2: 0.6497413573733606\n",
      "Similarity for row 3: 0.3738777690819517\n",
      "Similarity for row 4: 0.6446343057040622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(original, summarized):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([original, summarized])\n",
    "    return cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "\n",
    "# Calculate similarity for the first 5 rows\n",
    "for i in range(5):\n",
    "    similarity = calculate_similarity(df['content'][i], df['summary'][i])\n",
    "    print(f\"Similarity for row {i}: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "252a7b80-33ab-46f1-9b8b-22da9736ce2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: 2225\n",
      "Rows in CSV: 2225\n",
      "All files successfully processed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory path\n",
    "directory_path =  r\"E:\\Infosys project\\BBC News Summary\\Summaries\"\n",
    "\n",
    "# Count the number of text files in the directory\n",
    "file_count = sum(len(files) for _, _, files in os.walk(directory_path))\n",
    "\n",
    "# Compare with the number of rows in the CSV\n",
    "csv_row_count = len(df)\n",
    "\n",
    "print(f\"Files in directory: {file_count}\")\n",
    "print(f\"Rows in CSV: {csv_row_count}\")\n",
    "\n",
    "if file_count == csv_row_count:\n",
    "    print(\"All files successfully processed!\")\n",
    "else:\n",
    "    print(f\"Mismatch: {file_count - csv_row_count} files were not processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fe07a08-e4f5-4ada-89f2-c5e1ba3ee7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference summaries not found. ROUGE evaluation skipped.\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Evaluate summaries against reference summaries\n",
    "if 'reference_summary' in df.columns:\n",
    "    for i in range(5):  # Adjust for more rows\n",
    "        scores = scorer.score(df['reference_summary'][i], df['summary'][i])\n",
    "        print(f\"ROUGE scores for row {i}: {scores}\")\n",
    "else:\n",
    "    print(\"Reference summaries not found. ROUGE evaluation skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c601104-597d-4206-9e92-43e948952e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results saved!\n"
     ]
    }
   ],
   "source": [
    "# Save validation results to a file\n",
    "validation_results = {\n",
    "    \"files_in_directory\": file_count,\n",
    "    \"rows_in_csv\": csv_row_count,\n",
    "    \"status\": \"Success\" if file_count == csv_row_count else \"Mismatch\",\n",
    "}\n",
    "\n",
    "# Save as a JSON file\n",
    "import json\n",
    "with open(\"validation_results.json\", \"w\") as log_file:\n",
    "    json.dump(validation_results, log_file)\n",
    "\n",
    "print(\"Validation results saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04f96ac5-0942-4f34-a302-c31ce779e650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "No relevant summary found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the saved dataset\n",
    "data = pd.read_csv(\"extractive_summaries.csv\")\n",
    "\n",
    "def summarize_text(input_text):\n",
    "    \"\"\"\n",
    "    Function to summarize text using the preprocessed dataset.\n",
    "    \"\"\"\n",
    "    # Implement similarity or TF-IDF ranking logic here, or use the saved summaries\n",
    "    # For simplicity, we fetch summaries directly from the CSV.\n",
    "    # You can replace this with your summarization algorithm.\n",
    "    matched_row = data[data['content'].str.contains(input_text[:100], na=False)]\n",
    "    if not matched_row.empty:\n",
    "        return matched_row.iloc[0]['summary']\n",
    "    return \"No relevant summary found.\"\n",
    "\n",
    "# Example usage\n",
    "input_text = \"Type or paste a piece of text here for summarization...\"\n",
    "summary = summarize_text(input_text)\n",
    "print(f\"Summary:\\n{summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd34d692-23a8-4ed1-b51d-c00ad0ab4feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_28044\\612476297.py\", line 6, in summarize\n",
      "    summary = summarize_text(input_text)\n",
      "              ^^^^^^^^^^^^^^\n",
      "NameError: name 'summarize_text' is not defined\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import Text\n",
    "\n",
    "def summarize():\n",
    "    input_text = text_input.get(\"1.0\", \"end-1c\")\n",
    "    summary = summarize_text(input_text)\n",
    "    result_label.config(text=f\"Summary:\\n{summary}\")\n",
    "\n",
    "# Create the GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Text Summarization\")\n",
    "\n",
    "# Input Text Area\n",
    "text_input = Text(root, height=10, width=50)\n",
    "text_input.pack(pady=10)\n",
    "\n",
    "# Summarize Button\n",
    "summarize_button = tk.Button(root, text=\"Summarize\", command=summarize)\n",
    "summarize_button.pack(pady=5)\n",
    "\n",
    "# Output Label\n",
    "result_label = tk.Label(root, text=\"\", wraplength=400, justify=\"left\")\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6c469c9-4eab-4e55-8d69-b1353ae655c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.40.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.7.0)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.25.1)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (24.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (10.3.0)\n",
      "Collecting protobuf<6,>=3.20 (from streamlit)\n",
      "  Downloading protobuf-5.29.0-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (4.11.0)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.14.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.40.2-py2.py3-none-any.whl (8.6 MB)\n",
      "   ---------------------------------------- 0.0/8.6 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.4/8.6 MB 13.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.0/8.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.8/8.6 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.3/8.6 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.9/8.6 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.4/8.6 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.4/8.6 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.6/8.6 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/731.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 731.2/731.2 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading protobuf-5.29.0-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading pyarrow-18.1.0-cp311-cp311-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/25.1 MB 8.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.9/25.1 MB 7.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.7/25.1 MB 7.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.3/25.1 MB 7.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 8.1/25.1 MB 7.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.2/25.1 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.1/25.1 MB 8.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.9/25.1 MB 8.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.4/25.1 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.2/25.1 MB 7.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.0/25.1 MB 6.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 17.0/25.1 MB 6.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.8/25.1 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.9/25.1 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.9/25.1 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.0/25.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.0/25.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.3/25.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/25.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.6/6.9 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.1/6.9 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.7/6.9 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/6.9 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading narwhals-1.14.2-py3-none-any.whl (225 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, toml, tenacity, smmap, pyarrow, protobuf, narwhals, mdurl, cachetools, pydeck, markdown-it-py, gitdb, rich, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.5.0 cachetools-5.5.0 gitdb-4.0.11 gitpython-3.1.43 markdown-it-py-3.0.0 mdurl-0.1.2 narwhals-1.14.2 protobuf-5.29.0 pyarrow-18.1.0 pydeck-0.9.1 rich-13.9.4 smmap-5.0.1 streamlit-1.40.2 tenacity-9.0.0 toml-0.10.2 watchdog-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c17a80c6-b5f4-47d0-a8ba-d2744f876b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 13:10:52.089 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.475 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-11-28 13:10:52.477 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.478 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.480 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.482 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.483 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.484 Session state does not function when running a script without `streamlit run`\n",
      "2024-11-28 13:10:52.485 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.486 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.488 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.491 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.492 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.493 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-28 13:10:52.494 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"extractive_summaries.csv\")\n",
    "\n",
    "def summarize_text(input_text):\n",
    "    matched_row = data[data['content'].str.contains(input_text[:100], na=False)]\n",
    "    if not matched_row.empty:\n",
    "        return matched_row.iloc[0]['summary']\n",
    "    return \"No relevant summary found.\"\n",
    "\n",
    "# GUI Layout\n",
    "st.title(\"Text Summarization App\")\n",
    "st.subheader(\"Enter the text below:\")\n",
    "\n",
    "input_text = st.text_area(\"Your Text:\")\n",
    "if st.button(\"Summarize\"):\n",
    "    summary = summarize_text(input_text)\n",
    "    st.subheader(\"Summary:\")\n",
    "    st.write(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a033229-7791-4123-bcc5-15f65c60ed14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theme' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [\u001b[43mtheme\u001b[49m]\n\u001b[0;32m      2\u001b[0m primaryColor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#4CAF50\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m backgroundColor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#FFFFFF\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'theme' is not defined"
     ]
    }
   ],
   "source": [
    "[theme]\n",
    "primaryColor = \"#4CAF50\"\n",
    "backgroundColor = \"#FFFFFF\"\n",
    "secondaryBackgroundColor = \"#F5F5F5\"\n",
    "textColor = \"#000000\"\n",
    "font = \"sans serif\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b43db2e-e573-46d8-9755-500e8f5bb737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load system-generated summaries\n",
    "system_summaries_path = \"extractive_summaries.csv\"\n",
    "system_df = pd.read_csv(system_summaries_path)\n",
    "\n",
    "# Path to reference summaries\n",
    "reference_summaries_path = r\"E:\\Infosys project\\BBC News Summary\\Summaries\"\n",
    "\n",
    "# Read all reference summaries\n",
    "reference_data = []\n",
    "for root, _, files in os.walk(reference_summaries_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            reference_data.append({\"filename\": file, \"reference_summary\": content})\n",
    "\n",
    "# Create a DataFrame for reference summaries\n",
    "reference_df = pd.DataFrame(reference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24438d3b-2ae2-44e3-87bc-aad39aac8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure filenames in system_df match those in reference_df\n",
    "system_df['filename'] = system_df['filename'].str.strip()\n",
    "reference_df['filename'] = reference_df['filename'].str.strip()\n",
    "\n",
    "# Merge both DataFrames based on the filename\n",
    "merged_df = pd.merge(system_df, reference_df, on=\"filename\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "992fa582-ca8c-4e72-a9c1-a24ff2ded9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge-score in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge-score) (1.25.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge-score) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge-score) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->rouge-score) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56500401-fce5-4b28-8d96-f034c9577ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              rouge1  \\\n",
      "0  (0.5714285714285714, 0.23529411764705882, 0.33...   \n",
      "1   (0.2857142857142857, 0.18556701030927836, 0.225)   \n",
      "2  (0.42857142857142855, 0.1323529411764706, 0.20...   \n",
      "3  (0.2857142857142857, 0.1875, 0.22641509433962265)   \n",
      "4  (0.3333333333333333, 0.0707070707070707, 0.116...   \n",
      "\n",
      "                                              rouge2  \\\n",
      "0  (0.3225806451612903, 0.13157894736842105, 0.18...   \n",
      "1  (0.03225806451612903, 0.020833333333333332, 0....   \n",
      "2  (0.04838709677419355, 0.014778325123152709, 0....   \n",
      "3                                    (0.0, 0.0, 0.0)   \n",
      "4  (0.03225806451612903, 0.006756756756756757, 0....   \n",
      "\n",
      "                                              rougeL  \n",
      "0  (0.2857142857142857, 0.11764705882352941, 0.16...  \n",
      "1   (0.1746031746031746, 0.1134020618556701, 0.1375)  \n",
      "2  (0.2698412698412698, 0.08333333333333333, 0.12...  \n",
      "3  (0.15873015873015872, 0.10416666666666667, 0.1...  \n",
      "4  (0.25396825396825395, 0.05387205387205387, 0.0...  \n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Evaluate ROUGE scores for each summary pair\n",
    "results = []\n",
    "for _, row in merged_df.iterrows():\n",
    "    system_summary = row['summary']\n",
    "    reference_summary = row['reference_summary']\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    scores = scorer.score(reference_summary, system_summary)\n",
    "    results.append(scores)\n",
    "\n",
    "# Convert results to a DataFrame for analysis\n",
    "rouge_results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "print(rouge_results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "252b5139-b08b-4be1-9031-b9624b134bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE Scores:\n",
      "rouge-1    0.55\n",
      "rouge-2    0.35\n",
      "rouge-L    0.45\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biswa\\AppData\\Local\\Temp\\ipykernel_31720\\3150673154.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  flattened_df = rouge_results_df.applymap(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example of how `rouge_results_df` might look\n",
    "rouge_results_df = pd.DataFrame({\n",
    "    \"rouge-1\": [(0.5, 0.4, 0.6), (0.6, 0.5, 0.7)],\n",
    "    \"rouge-2\": [(0.3, 0.2, 0.4), (0.4, 0.3, 0.5)],\n",
    "    \"rouge-L\": [(0.4, 0.3, 0.5), (0.5, 0.4, 0.6)]\n",
    "})\n",
    "\n",
    "# Convert tuples/lists to their mean values\n",
    "flattened_df = rouge_results_df.applymap(\n",
    "    lambda x: x[0] if isinstance(x, (tuple, list)) else x\n",
    ")\n",
    "\n",
    "# Now calculate the average scores\n",
    "average_scores = flattened_df.mean()\n",
    "print(\"Average ROUGE Scores:\")\n",
    "print(average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6275e9bb-efab-41d0-97b4-bd4779603051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-13 10:02:52.119 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-12-13 10:02:52.123 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.278 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\biswa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-12-13 10:02:53.280 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.281 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.283 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.286 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.287 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.288 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.289 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.290 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.291 Session state does not function when running a script without `streamlit run`\n",
      "2024-12-13 10:02:53.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.293 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.294 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.295 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.297 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.299 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 10:02:53.300 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nBartForConditionalGeneration requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFBartForConditionalGeneration\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m option \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39mselectbox(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChoose an action:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mView Summaries\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerate Summary\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Load the model and tokenizer\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m option \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mView Summaries\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Load the saved CSV file\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     df \u001b[38;5;241m=\u001b[39m load_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextractive_summaries.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py:217\u001b[0m, in \u001b[0;36mCachedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mshow_spinner \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mshow_spinner, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m spinner(message, _cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_or_create_cached_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_or_create_cached_value(args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py:242\u001b[0m, in \u001b[0;36mCachedFunc._get_or_create_cached_value\u001b[1;34m(self, func_args, func_kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m     cached_result \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mread_result(value_key)\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_cache_hit(cached_result)\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_cache_miss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py:299\u001b[0m, in \u001b[0;36mCachedFunc._handle_cache_miss\u001b[1;34m(self, cache, value_key, func_args, func_kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# We acquired the lock before any other thread. Compute the value!\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mcached_message_replay_ctx\u001b[38;5;241m.\u001b[39mcalling_cached_function(\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    298\u001b[0m ):\n\u001b[1;32m--> 299\u001b[0m     computed_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# We've computed our value, and now we need to write it back to the cache\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# along with any \"replay messages\" that were generated during value computation.\u001b[39;00m\n\u001b[0;32m    303\u001b[0m messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mcached_message_replay_ctx\u001b[38;5;241m.\u001b[39m_most_recent_messages\n",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;129m@st\u001b[39m\u001b[38;5;241m.\u001b[39mcache_resource\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m():\n\u001b[1;32m---> 13\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mBartForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_your_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m BartTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_your_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, tokenizer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1666\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1666\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1645\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1643\u001b[0m \u001b[38;5;66;03m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[0;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m is_tf_available():\n\u001b[1;32m-> 1645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[0;32m   1648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[1;31mImportError\u001b[0m: \nBartForConditionalGeneration requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFBartForConditionalGeneration\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# Load the CSV file\n",
    "@st.cache_data\n",
    "def load_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    model = BartForConditionalGeneration.from_pretrained(\"path_to_your_model\")\n",
    "    tokenizer = BartTokenizer.from_pretrained(\"path_to_your_model\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to generate summaries\n",
    "def generate_summary(text, model, tokenizer, max_length=130, min_length=30, length_penalty=2.0, num_beams=4):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        length_penalty=length_penalty,\n",
    "        num_beams=num_beams\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Streamlit app layout\n",
    "st.title(\"Text Summarization Tool\")\n",
    "st.write(\"View summaries from the dataset or generate new ones!\")\n",
    "\n",
    "# Sidebar for navigation\n",
    "option = st.sidebar.selectbox(\"Choose an action:\", [\"View Summaries\", \"Generate Summary\"])\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model, tokenizer = load_model()\n",
    "\n",
    "if option == \"View Summaries\":\n",
    "    # Load the saved CSV file\n",
    "    df = load_csv(\"extractive_summaries.csv\")\n",
    "\n",
    "    # Display summaries\n",
    "    st.subheader(\"Summaries from the Dataset\")\n",
    "    st.dataframe(df)\n",
    "\n",
    "    # Search by filename or content\n",
    "    search_text = st.text_input(\"Search summaries by filename or content:\")\n",
    "    if search_text.strip():\n",
    "        filtered_df = df[df['content'].str.contains(search_text, case=False, na=False) | df['filename'].str.contains(search_text, case=False, na=False)]\n",
    "        st.write(f\"Found {len(filtered_df)} matching results:\")\n",
    "        st.dataframe(filtered_df)\n",
    "\n",
    "elif option == \"Generate Summary\":\n",
    "    # Text input for new summary\n",
    "    st.subheader(\"Generate a New Summary\")\n",
    "    input_text = st.text_area(\"Enter the text to summarize\", height=200)\n",
    "    \n",
    "    if st.button(\"Summarize\"):\n",
    "        if input_text.strip():\n",
    "            st.write(\"Generating summary...\")\n",
    "            summary = generate_summary(input_text, model, tokenizer)\n",
    "            st.subheader(\"Generated Summary:\")\n",
    "            st.write(summary)\n",
    "        else:\n",
    "            st.warning(\"Please enter some text to summarize.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d06f523-81c3-4aec-ad94-c3369a52a398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.24.0->transformers)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/10.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.0/10.1 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.6/10.1 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.1 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Downloading safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Installing collected packages: safetensors, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.10.0 huggingface-hub-0.26.5 safetensors-0.4.5 tokenizers-0.21.0 transformers-4.47.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566ca9a5-cc04-461c-9166-8cc638bd0565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.5.1%2Bcpu-cp311-cp311-win_amd64.whl (205.5 MB)\n",
      "     ---------------------------------------- 0.0/205.5 MB ? eta -:--:--\n",
      "     --------------------------------------- 1.6/205.5 MB 10.5 MB/s eta 0:00:20\n",
      "      -------------------------------------- 3.9/205.5 MB 11.2 MB/s eta 0:00:19\n",
      "     - ------------------------------------- 6.8/205.5 MB 12.0 MB/s eta 0:00:17\n",
      "     - ------------------------------------- 9.4/205.5 MB 12.0 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 11.8/205.5 MB 11.9 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 12.3/205.5 MB 11.9 MB/s eta 0:00:17\n",
      "     -- ----------------------------------- 15.2/205.5 MB 11.0 MB/s eta 0:00:18\n",
      "     --- ---------------------------------- 17.6/205.5 MB 11.1 MB/s eta 0:00:17\n",
      "     --- ---------------------------------- 19.9/205.5 MB 11.1 MB/s eta 0:00:17\n",
      "     ---- --------------------------------- 22.5/205.5 MB 11.2 MB/s eta 0:00:17\n",
      "     ---- --------------------------------- 24.9/205.5 MB 11.3 MB/s eta 0:00:16\n",
      "     ---- --------------------------------- 27.0/205.5 MB 11.3 MB/s eta 0:00:16\n",
      "     ----- -------------------------------- 29.9/205.5 MB 11.4 MB/s eta 0:00:16\n",
      "     ----- -------------------------------- 32.2/205.5 MB 11.5 MB/s eta 0:00:16\n",
      "     ------ ------------------------------- 34.9/205.5 MB 11.5 MB/s eta 0:00:15\n",
      "     ------ ------------------------------- 37.2/205.5 MB 11.5 MB/s eta 0:00:15\n",
      "     ------- ------------------------------ 39.6/205.5 MB 11.5 MB/s eta 0:00:15\n",
      "     ------- ------------------------------ 41.9/205.5 MB 11.5 MB/s eta 0:00:15\n",
      "     -------- ----------------------------- 44.6/205.5 MB 11.6 MB/s eta 0:00:14\n",
      "     -------- ----------------------------- 46.1/205.5 MB 11.6 MB/s eta 0:00:14\n",
      "     -------- ----------------------------- 46.1/205.5 MB 11.6 MB/s eta 0:00:14\n",
      "     -------- ----------------------------- 46.1/205.5 MB 11.6 MB/s eta 0:00:14\n",
      "     --------- ---------------------------- 49.8/205.5 MB 10.7 MB/s eta 0:00:15\n",
      "     --------- ---------------------------- 51.6/205.5 MB 10.6 MB/s eta 0:00:15\n",
      "     ---------- --------------------------- 55.1/205.5 MB 10.8 MB/s eta 0:00:14\n",
      "     ---------- --------------------------- 57.7/205.5 MB 10.8 MB/s eta 0:00:14\n",
      "     ----------- -------------------------- 60.3/205.5 MB 10.9 MB/s eta 0:00:14\n",
      "     ----------- -------------------------- 62.7/205.5 MB 10.9 MB/s eta 0:00:14\n",
      "     ------------ ------------------------- 65.3/205.5 MB 10.9 MB/s eta 0:00:13\n",
      "     ------------ ------------------------- 67.6/205.5 MB 11.0 MB/s eta 0:00:13\n",
      "     ------------ ------------------------- 70.0/205.5 MB 11.0 MB/s eta 0:00:13\n",
      "     ------------- ------------------------ 72.4/205.5 MB 11.0 MB/s eta 0:00:13\n",
      "     ------------- ------------------------ 74.4/205.5 MB 11.0 MB/s eta 0:00:12\n",
      "     -------------- ----------------------- 76.8/205.5 MB 11.0 MB/s eta 0:00:12\n",
      "     -------------- ----------------------- 79.7/205.5 MB 11.1 MB/s eta 0:00:12\n",
      "     --------------- ---------------------- 82.1/205.5 MB 11.1 MB/s eta 0:00:12\n",
      "     --------------- ---------------------- 84.1/205.5 MB 11.1 MB/s eta 0:00:11\n",
      "     --------------- ---------------------- 86.0/205.5 MB 11.0 MB/s eta 0:00:11\n",
      "     ---------------- --------------------- 87.8/205.5 MB 10.9 MB/s eta 0:00:11\n",
      "     ---------------- --------------------- 89.7/205.5 MB 10.9 MB/s eta 0:00:11\n",
      "     ----------------- -------------------- 92.3/205.5 MB 11.0 MB/s eta 0:00:11\n",
      "     ----------------- -------------------- 94.9/205.5 MB 11.0 MB/s eta 0:00:11\n",
      "     ----------------- -------------------- 97.3/205.5 MB 11.0 MB/s eta 0:00:10\n",
      "     ------------------ ------------------- 99.9/205.5 MB 11.1 MB/s eta 0:00:10\n",
      "     ------------------ ------------------ 102.5/205.5 MB 11.1 MB/s eta 0:00:10\n",
      "     ------------------ ------------------ 104.1/205.5 MB 11.0 MB/s eta 0:00:10\n",
      "     ------------------- ----------------- 106.4/205.5 MB 11.0 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 109.3/205.5 MB 11.1 MB/s eta 0:00:09\n",
      "     ------------------- ----------------- 110.9/205.5 MB 11.1 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 111.1/205.5 MB 10.8 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 111.1/205.5 MB 10.8 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 111.1/205.5 MB 10.8 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 111.1/205.5 MB 10.8 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 114.3/205.5 MB 10.3 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 116.4/205.5 MB 10.3 MB/s eta 0:00:09\n",
      "     --------------------- --------------- 119.3/205.5 MB 10.4 MB/s eta 0:00:09\n",
      "     --------------------- --------------- 121.9/205.5 MB 10.4 MB/s eta 0:00:09\n",
      "     ---------------------- -------------- 124.3/205.5 MB 10.4 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 125.8/205.5 MB 10.4 MB/s eta 0:00:08\n",
      "     ----------------------- ------------- 128.7/205.5 MB 10.4 MB/s eta 0:00:08\n",
      "     ----------------------- ------------- 131.1/205.5 MB 10.5 MB/s eta 0:00:08\n",
      "     ------------------------ ------------ 133.7/205.5 MB 10.5 MB/s eta 0:00:07\n",
      "     ------------------------ ------------ 136.1/205.5 MB 10.5 MB/s eta 0:00:07\n",
      "     ------------------------ ------------ 138.4/205.5 MB 10.5 MB/s eta 0:00:07\n",
      "     ------------------------- ----------- 140.8/205.5 MB 10.5 MB/s eta 0:00:07\n",
      "     ------------------------- ----------- 142.9/205.5 MB 10.6 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 142.9/205.5 MB 10.6 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 142.9/205.5 MB 10.6 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 142.9/205.5 MB 10.6 MB/s eta 0:00:06\n",
      "     ------------------------- ----------- 142.9/205.5 MB 10.6 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 146.8/205.5 MB 10.1 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 148.6/205.5 MB 10.1 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 151.5/205.5 MB 10.1 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 153.4/205.5 MB 10.1 MB/s eta 0:00:06\n",
      "     ---------------------------- -------- 155.7/205.5 MB 10.1 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 158.1/205.5 MB 10.1 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 160.2/205.5 MB 10.1 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 162.3/205.5 MB 10.1 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 164.4/205.5 MB 10.1 MB/s eta 0:00:05\n",
      "     ------------------------------ ------ 166.7/205.5 MB 10.1 MB/s eta 0:00:04\n",
      "     ------------------------------ ------ 169.1/205.5 MB 10.2 MB/s eta 0:00:04\n",
      "     ------------------------------ ------ 171.4/205.5 MB 10.2 MB/s eta 0:00:04\n",
      "     ------------------------------- ----- 173.5/205.5 MB 10.2 MB/s eta 0:00:04\n",
      "     ------------------------------- ----- 176.2/205.5 MB 10.2 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 176.9/205.5 MB 10.2 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 180.6/205.5 MB 10.2 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 182.7/205.5 MB 10.2 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 185.1/205.5 MB 10.2 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 187.7/205.5 MB 10.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 190.1/205.5 MB 10.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 192.4/205.5 MB 10.3 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 195.0/205.5 MB 10.3 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 197.7/205.5 MB 10.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.0/205.5 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  202.4/205.5 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  204.2/205.5 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  205.3/205.5 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  205.3/205.5 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  205.3/205.5 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  205.3/205.5 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  205.3/205.5 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  205.3/205.5 MB 10.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 205.5/205.5 MB 9.7 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.20.1%2Bcpu-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ------------- -------------------------- 0.5/1.6 MB ? eta -:--:--\n",
      "     --------------------------------- ------ 1.3/1.6 MB 6.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.3/1.6 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.6/1.6 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.5.1%2Bcpu-cp311-cp311-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.4/2.4 MB 11.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "     ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "     ---------------- ----------------------- 2.6/6.2 MB 13.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 5.0/6.2 MB 11.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.2/6.2 MB 11.9 MB/s eta 0:00:00\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 536.2/536.2 kB 8.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\biswa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Installing collected packages: mpmath, sympy, torch, torchvision, torchaudio\n",
      "Successfully installed mpmath-1.3.0 sympy-1.13.1 torch-2.5.1+cpu torchaudio-2.5.1+cpu torchvision-0.20.1+cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3bde5c-1efe-4acc-955b-77fb7210cc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36be434-3591-4094-b98d-9814fae49ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
